{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fwi_predict.constants import TZ_STRING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara_raw = pd.read_excel(\"../data/raw/All ARA Data until March 31, 2024.xlsx\", sheet_name='Sheet1')\n",
    "var_dict = pd.read_excel(\"../data/raw/All ARA Data until March 31, 2024.xlsx\", sheet_name='Sheet2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unique identified should be the pond ID and sample datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Group\n",
       "ARA V1 (2-weekly)                    2643\n",
       "ARA V1.2 (regular-monthly)           1889\n",
       "Regular ARA pond                     1117\n",
       "Feed Holiday Efficacy Test (2023)     563\n",
       "Focus Group 4                         215\n",
       "ARA V1.2 (in-depth-weekly)            209\n",
       "Focus Group 3                         190\n",
       "Test A (Farmer Measurements)           84\n",
       "Test A (Water Sample Analysis)         43\n",
       "Focus Group 2                          24\n",
       "Test B                                 16\n",
       "Focus Group 1                           4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ara_raw['Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def is_str(x) -> bool:\n",
    "    return isinstance(x, str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_map = {\n",
    "    'Date of Data Collection': 'date',\n",
    "    'Pond ID': 'pond_id',\n",
    "    'Measurement Type': 'time_of_day',\n",
    "    'Group': 'group',\n",
    "    'Pond Type': 'treatment_group',\n",
    "    'Time (sample or data collection)': 'sample_time',\n",
    "    'Name': 'name', # Is this the owner?\n",
    "    'Which meter are you using?': 'measure_instrument',\n",
    "    'Follow-up': 'follow_up',\n",
    "    'Weather': 'weather',\n",
    "    'Dissolved Oxygen (mg/L)': 'do_mg_per_L',\n",
    "    'pH': 'ph',\n",
    "    'Turbidity (cm)': 'turbidity_cm',\n",
    "    'Ammonia (mg/L)': 'ammonia_mg_per_L',\n",
    "    'Water quality in the *required* range': 'in_range',\n",
    "    'Parameter(s) out of range': 'params_out_of_range',\n",
    "    'Temperature (°C)': 'temperature_celsius',\n",
    "    'Conductivity (ms)': 'conductivity_ms',\n",
    "    'TDS (ppt)': 'tds_ppt',\n",
    "    'Water Color': 'water_color',\n",
    "    'Corrective actions requested': 'corrective_actions_requested',\n",
    "    'Amount requested': 'amount_requested',\n",
    "    'Corrective actions implementation': 'corrective_actions_implementation',\n",
    "    'Corrective actions implementation date': 'corrective_actions_implementation_date',\n",
    "    'Corrective actions taken': 'corrective_actions_taken',\n",
    "    'Non-prescribed actions taken': 'non_prescribed_actions_taken',\n",
    "    'If the farmer didn\\'t apply corrective actions, what were the reasons?': 'no_corrective_reasons',\n",
    "    'Improvement of *targeted* water quality parameters': 'targeted_params_improvement',\n",
    "    'Notes (corrective actions)': 'corrective_action_notes',\n",
    "    'Individuals air gulping': 'individuals_air_gulping',\n",
    "    'Individuals tail splashing': 'individuals_tail_splashing',\n",
    "    'Dead fish': 'dead_fish',\n",
    "    'Notes (mortalities)': 'mortalities_notes',\n",
    "    'Feed amount (kg)': 'feed_amount_kg',\n",
    "    'Did we help the fish?': 'did_we_help_the_fish',\n",
    "    'Stocking density (fish per acre)': 'fish_per_acre',\n",
    "    'Species': 'species',\n",
    "    'Weight': 'weight', # Need to find units\n",
    "    'Notes (additional info)': 'additional_info',\n",
    "    'Any pictures you want to share?': 'pictures',\n",
    "    'Data tool Sr. No.': 'serial_no_data_tool',\n",
    "    'Winkler\\'s Method Used for DO': 'winklers_method',\n",
    "    'Feed type': 'feed_type',\n",
    "    'Days without feed since the last measurement': 'days_without_feed_since_last_measurement',\n",
    "    'Chlorophyll-a': 'chl-a',\n",
    "    'Phycocyanin': 'phycocyanin',\n",
    "    'Plankton Sample Analysis Date': 'plankton_sample_analysis_date',\n",
    "    'Total n° of cells / 1L': 'cells_per_L',\n",
    "    'Submission ID': 'submission_id', # Probably refer to plankton sample\n",
    "    'Dead fish found by the FARMER since the last visit': 'dead_fish_since_last_visit_farmer_report',\n",
    "    'Dead fish found by YOU today': 'dead_fish_found_fwi',\n",
    "    'How many locations?': 'num_locations', # Is this the number of sampling locations?\n",
    "    'Prescribed collection date': 'prescribed_collection_date',\n",
    "    'Reason for late or no collection (if any)': 'no_or_late_collection_reason',\n",
    "    'Did the farmer collect the measurement?': 'farmer_collected_measurement',\n",
    "    'Turbidity (farmer measurement)': 'turbidity_farmer',\n",
    "    'Temperature (farmer measurement)': 'temperature_farmer',\n",
    "    'pH (farmer measurement)': 'ph_farmer',\n",
    "    'Feed given today': 'feed_given_today',\n",
    "    'Time (sample analysis)': 'sample_analysis_time',\n",
    "    '1. Dissolved Oxygen (mg/L)': 'do_mg_per_L_1',\n",
    "    '2. Dissolved Oxygen (mg/L)': 'do_mg_per_L_2',\n",
    "    '3. Dissolved Oxygen (mg/L)': 'do_mg_per_L_3',\n",
    "    '1. pH': 'ph_1',\n",
    "    '2. pH': 'ph_2',\n",
    "    '3. pH': 'ph_3',\n",
    "    '1. Temperature (in °C)': 'temperature_celsius_1',\n",
    "    '2. Temperature (in °C)': 'temperature_celsius_2',\n",
    "    '3. Temperature (in °C)': 'temperature_celsius_3',\n",
    "    'Light bottle DO (NPP)': 'light_bottle_do_npp',\n",
    "    'Dark bottle DO (R)': 'dark_bottle_do_R',\n",
    "    'Outcomes of corrective actions': 'corrective_actions_outcome',\n",
    "    'Salinity (ppt)': 'salinity_ppt',\n",
    "    'Feeding': 'feeding',\n",
    "    'Air gulping': 'air_gulping',\n",
    "    'Primary Productivity GPP (mg/L)': 'primary_productivity_gpp_mg_per_L',\n",
    "    'Alkalinity': 'alkalinity',\n",
    "    'How did the farmer find implementing the corrective actions?': 'corrective_actions_farmer_ease',\n",
    "    'Tail splashing': 'tail_splashing',\n",
    "    'How many fish did we help?': 'fish_helped',\n",
    "    'How did we help the fish?': 'fish_help_method',\n",
    "    'Readings communicated today': 'readings_communicated_today',\n",
    "    'Actions taken': 'actions_taken',\n",
    "    'Details': 'details',\n",
    "    'Wind': 'wind',\n",
    "    'Disease outbreak': 'disease_outbreak',\n",
    "    'Lice infestation': 'lice_infestation',\n",
    "    'Vegetation (1+ cm into the water)': 'vegetation_in_water'\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara = ara_raw.rename(columns=column_map)\n",
    "assert(ara.columns.isin(column_map.values()).all()) # Assert column names standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean sample times\n",
    "ara['sample_time'].apply(type).value_counts() \n",
    "str_formatted = ara['sample_time'].apply(is_str)\n",
    "ara.loc[str_formatted, 'sample_time'] # Find string formatted times\n",
    "ara.loc[str_formatted, 'sample_time'] = ara.loc[str_formatted, 'sample_time'] + ':00' # Add seconds\n",
    "ara.loc[~str_formatted  & ara['sample_time'].notna(), 'sample_time'] = \\\n",
    "    ara.loc[~str_formatted & ara['sample_time'].notna(), 'sample_time'].apply(lambda x: x.strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['sample_dt'] = pd.to_datetime(ara['date'].dt.strftime(\"%Y-%m-%d\") + ' ' + ara['sample_time'], errors='coerce')\n",
    "ara['sample_dt'] = ara['sample_dt'].dt.tz_localize(TZ_STRING) # Add timezone\n",
    "ara = ara.drop(columns=['date', 'sample_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_no_map = {\n",
    "    'Yes': True,\n",
    "    'No': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "follow_up\n",
       "False    5288\n",
       "True      768\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ara['follow_up'] = ara['follow_up'].map(yes_no_map)\n",
    "ara['follow_up'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['turbidity_cm'].apply(type).value_counts(dropna=False)\n",
    "str_formatted = ara['turbidity_cm'].apply(is_str)\n",
    "ara.loc[str_formatted, 'turbidity_cm'] = np.nan\n",
    "ara['turbidity_cm'] = ara['turbidity_cm'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['ammonia_mg_per_L'].apply(type).value_counts(dropna=False)\n",
    "str_formatted = ara['ammonia_mg_per_L'].apply(is_str)\n",
    "ara.loc[str_formatted, 'ammonia_mg_per_L'] = np.nan\n",
    "ara['ammonia_mg_per_L'] = ara['ammonia_mg_per_L'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['in_range'] = ara['in_range'].map(yes_no_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "params_out_of_range\n",
       "Dissolved oxygen                                       852\n",
       "pH                                                     245\n",
       "Dissolved oxygen\\npH                                   166\n",
       "Dissolved oxygen\\nTurbidity                             52\n",
       "Turbidity                                               44\n",
       "Dissolved oxygen\\nAmmonia                               31\n",
       "Dissolved oxygen\\npH\\nAmmonia                           27\n",
       "Ph                                                      24\n",
       "Ammonia                                                 20\n",
       "Dissolved Oxygen                                        18\n",
       "pH\\nAmmonia                                             17\n",
       "Dissolved oxygen\\npH\\nAmmonia\\nPrimary productivity     12\n",
       "pH\\nAmmonia\\nPrimary productivity                        7\n",
       "Dissolved oxygen\\nAmmonia\\nPrimary productivity          7\n",
       "Dissolved Oxygen, Ph                                     7\n",
       "pH\\nDissolved oxygen                                     7\n",
       "Dissolved oxygen\\nPrimary productivity                   6\n",
       "pH\\nAmmonia\\nDissolved oxygen                            2\n",
       "pH\\nTurbidity                                            2\n",
       "Primary productivity                                     2\n",
       "Ammonia\\nDissolved oxygen                                2\n",
       "Dissolved oxygen\\npH\\nTurbidity                          2\n",
       "Dissolved oxygen\\npH\\nPrimary productivity               2\n",
       "Dissolved Oxygen, Ammonia                                1\n",
       "Ph, Ammonia                                              1\n",
       "Ammonia\\nTurbidity                                       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ara['params_out_of_range'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later create own OOR variables and drop this var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['temperature_celsius'].apply(type).value_counts()\n",
    "str_formatted = ara['temperature_celsius'].apply(is_str)\n",
    "ara.loc[str_formatted, 'temperature_celsius'] = np.nan # Str formatted temperature is illegible so setting to nan.\n",
    "ara['temperature_celsius'] = ara['temperature_celsius'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['conductivity_ms'].value_counts()\n",
    "ara['conductivity_ms'].apply(type).value_counts()\n",
    "str_formatted = ara['conductivity_ms'].apply(is_str)\n",
    "ara.loc[str_formatted, 'conductivity_ms'] = ara.loc[str_formatted, 'conductivity_ms'] \\\n",
    "    .str.replace('o', '0') \\\n",
    "    .str.replace('`', '') \\\n",
    "    .str.replace(' ', '') \\\n",
    "    .str.replace('\\'', '.')\n",
    "ara['conductivity_ms'] = ara['conductivity_ms'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['tds_ppt'].apply(type).value_counts()\n",
    "str_formatted = ara['tds_ppt'].apply(is_str)\n",
    "ara.loc[str_formatted, 'tds_ppt'] = ara.loc[str_formatted, 'tds_ppt'] \\\n",
    "    .str.replace('`', '') \\\n",
    "    .str.replace('l', '1')\n",
    "ara['tds_ppt'] = ara['tds_ppt'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "water_color\n",
       "Light green                                2264\n",
       "Dark green                                 2143\n",
       "Light brown                                 822\n",
       "Saturated green                             501\n",
       "NaN                                         387\n",
       "Transparent                                 282\n",
       "Green                                       235\n",
       "Brown                                       107\n",
       "Brownish                                     68\n",
       "Dark brown                                   42\n",
       "White / Transparent                          41\n",
       "White/transparent                            33\n",
       "Yellowish brown                              22\n",
       "brown                                        21\n",
       "White                                        17\n",
       "green                                        15\n",
       "Rusty brown                                   9\n",
       "Light Green                                   5\n",
       "dark green                                    4\n",
       "Blue-green                                    3\n",
       "Greenish                                      3\n",
       "Dark Green                                    3\n",
       "Brownish green                                3\n",
       "Little dark green                             2\n",
       "greenish                                      2\n",
       "Pale Green                                    1\n",
       "GREEN                                         1\n",
       "Greenish brown                                1\n",
       "Light Green and some sediment turbidity       1\n",
       "Bright green                                  1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ara['water_color'].value_counts(dropna=False) # Not important to clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['feed_amount_kg'].value_counts() # Complicated so won't try to convert to numeric\n",
    "ara['did_we_help_the_fish'] = ara['did_we_help_the_fish'].map(yes_no_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['fish_per_acre'].value_counts()\n",
    "ara['fish_per_acre'].apply(type).value_counts()\n",
    "str_formatted = ara['fish_per_acre'].apply(is_str)\n",
    "ara.loc[str_formatted, 'fish_per_acre'] = np.nan\n",
    "ara['fish_per_acre'] = ara['fish_per_acre'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1610    gra\n",
       "3594    2KG\n",
       "Name: weight, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ask about units\n",
    "ara['weight'].value_counts()\n",
    "ara['weight'].apply(type).value_counts()\n",
    "str_formatted = ara['weight'].apply(is_str)\n",
    "ara.loc[str_formatted, 'weight'] # One gives units in kg so only clean after askings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['winklers_method'] = ara['winklers_method'].map(yes_no_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['days_without_feed_since_last_measurement'].apply(type).value_counts()\n",
    "str_formatted = ara['days_without_feed_since_last_measurement'].apply(is_str)\n",
    "ara.loc[str_formatted, 'days_without_feed_since_last_measurement']\n",
    "ara.loc[ara['days_without_feed_since_last_measurement'].str.contains('second day') &\n",
    "        ara['days_without_feed_since_last_measurement'].notna(), # Fix later\n",
    "        'days_without_feed_since_last_measurement'] = 2\n",
    "ara.loc[ara['days_without_feed_since_last_measurement'].str.contains('once') &\n",
    "        ara['days_without_feed_since_last_measurement'].notna(),\n",
    "        'days_without_feed_since_last_measurement'] = np.nan # Set 'Weekly once' to null for now\n",
    "ara['days_without_feed_since_last_measurement'] = ara['days_without_feed_since_last_measurement'].astype(float)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['dead_fish_since_last_visit_farmer_report'].value_counts()\n",
    "ara['dead_fish_since_last_visit_farmer_report'].apply(type).value_counts()\n",
    "str_formatted = ara['dead_fish_since_last_visit_farmer_report'].apply(is_str)\n",
    "ara.loc[str_formatted, 'dead_fish_since_last_visit_farmer_report'] = 0\n",
    "ara['dead_fish_since_last_visit_farmer_report'] = ara['dead_fish_since_last_visit_farmer_report'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara.loc[ara['num_locations'].str.contains('1') & ara['num_locations'].notna(), 'num_locations'] = 1\n",
    "ara['num_locations'] = ara['num_locations'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['prescribed_collection_date'].value_counts()\n",
    "str_formatted = ara['prescribed_collection_date'].apply(is_str)\n",
    "ara.loc[str_formatted, 'prescribed_collection_date'] = ara.loc[str_formatted, 'prescribed_collection_date'] \\\n",
    "    .str.extract('(\\\\d{2}/\\\\d{2}/\\\\d{4})') \\\n",
    "    .squeeze() \\\n",
    "    .pipe(pd.to_datetime)\n",
    "ara['prescribed_collection_date'] = ara['prescribed_collection_date'].astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['feed_given_today'] = ara['feed_given_today'].map(yes_no_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sample_analysis_time\n",
       "<class 'float'>            6984\n",
       "<class 'datetime.time'>      55\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ara['sample_analysis_time'].value_counts()\n",
    "ara['sample_analysis_time'].apply(type).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['do_mg_per_L_1'].apply(type).value_counts()\n",
    "str_formatted = ara['do_mg_per_L_1'].apply(is_str)\n",
    "ara.loc[str_formatted, 'do_mg_per_L_1'] = ara.loc[str_formatted, 'do_mg_per_L_1'] \\\n",
    "    .str.replace(' ', '') \\\n",
    "    .str.replace('O', '0')\n",
    "ara['do_mg_per_L_1'] = ara['do_mg_per_L_1'].astype(float)\n",
    "\n",
    "ara['temperature_celsius_1'].apply(type).value_counts()\n",
    "str_formatted = ara['temperature_celsius_1'].apply(is_str)\n",
    "ara.loc[str_formatted, 'temperature_celsius_1'] = ara.loc[str_formatted, 'temperature_celsius_1'] \\\n",
    "    .str.replace('..', '.') \\\n",
    "    .str.replace(' ', '')\n",
    "ara['temperature_celsius_1'] = ara['temperature_celsius_1'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['light_bottle_do_npp'].value_counts()\n",
    "ara['light_bottle_do_npp'].apply(type).value_counts()\n",
    "str_formatted = ara['light_bottle_do_npp'].apply(is_str)\n",
    "ara.loc[str_formatted, 'light_bottle_do_npp'] = ara.loc[str_formatted, 'light_bottle_do_npp'] \\\n",
    "    .str.replace('`', '') \\\n",
    "    .replace('NC', np.nan)\n",
    "ara['light_bottle_do_npp'] = ara['light_bottle_do_npp'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['dark_bottle_do_R'].apply(type).value_counts()\n",
    "str_formatted = ara['dark_bottle_do_R'].apply(is_str)\n",
    "ara.loc[str_formatted, 'dark_bottle_do_R'] = ara.loc[str_formatted, 'dark_bottle_do_R'] \\\n",
    "    .str.replace('o', '0') \\\n",
    "    .replace('NC', np.nan)\n",
    "ara['dark_bottle_do_R'] = ara['dark_bottle_do_R'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['salinity_ppt'].value_counts()\n",
    "ara['salinity_ppt'].apply(type).value_counts()\n",
    "str_formatted = ara['salinity_ppt'].apply(is_str)\n",
    "ara.loc[str_formatted, 'salinity_ppt'] = ara.loc[str_formatted, 'salinity_ppt'] \\\n",
    "    .str.replace(' ', '') \\\n",
    "    .str.replace(',', '.')\n",
    "ara['salinity_ppt'] = ara['salinity_ppt'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['primary_productivity_gpp_mg_per_L'].value_counts()\n",
    "ara['primary_productivity_gpp_mg_per_L'].apply(type).value_counts()\n",
    "str_formatted = ara['primary_productivity_gpp_mg_per_L'].apply(is_str)\n",
    "ara.loc[str_formatted, 'primary_productivity_gpp_mg_per_L'] = np.nan # All unintelligible\n",
    "ara['primary_productivity_gpp_mg_per_L'] = ara['primary_productivity_gpp_mg_per_L'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['readings_communicated_today'] = ara['readings_communicated_today'].map(yes_no_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['disease_outbreak'] = ara['disease_outbreak'].map(yes_no_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "disease_outbreak\n",
       "NaN      4988\n",
       "False    2038\n",
       "True       13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ara['disease_outbreak'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['lice_infestation'] = ara['lice_infestation'].map(yes_no_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ara['vegetation_in_water'] = ara['vegetation_in_water'].map(yes_no_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_duplicates(\n",
    "    df, id_cols, string_delimiter=\"; \", mark_column=\"had_duplicates\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Resolve duplicates in a DataFrame, marking which rows had duplicates and resolving conflicts.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing duplicates.\n",
    "        id_cols (list): List of columns defining the unique ID.\n",
    "        string_delimiter (str, optional): Delimiter to concatenate strings.\n",
    "        mark_column (str, optional): Name of the column to indicate duplicates.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with duplicates resolved and marked.\n",
    "    \"\"\"\n",
    "    def resolve_group(group):\n",
    "        resolved = {}\n",
    "        for col in group.columns:\n",
    "            if col in id_cols:\n",
    "                # Keep ID columns as is\n",
    "                resolved[col] = group[col].iloc[0]\n",
    "            else:\n",
    "                if pd.api.types.is_numeric_dtype(group[col]):\n",
    "                    # Resolve numeric columns by mean, ignoring NaNs\n",
    "                    resolved[col] = group[col].mean(skipna=True)\n",
    "                elif pd.api.types.is_string_dtype(group[col]):\n",
    "                    # Resolve string columns by concatenating unique values\n",
    "                    unique_strings = group[col].dropna().unique()\n",
    "                    resolved[col] = string_delimiter.join(unique_strings)\n",
    "                else:\n",
    "                    # Cast other types to strings and concatenate unique values\n",
    "                    unique_values = group[col].dropna().astype(str).unique()\n",
    "                    resolved[col] = string_delimiter.join(unique_values)\n",
    "        \n",
    "        # Mark duplicates if the group contains more than one row\n",
    "        resolved[mark_column] = len(group) > 1\n",
    "        return pd.Series(resolved)\n",
    "\n",
    "    # Apply resolution to each group\n",
    "    resolved_df = (\n",
    "        df.groupby(id_cols)\n",
    "        .apply(resolve_group, include_groups=False)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    return resolved_df\n",
    "\n",
    "\n",
    "def find_conflicting_duplicates(df, id_cols):\n",
    "    \"\"\"\n",
    "    Identify duplicates with conflicting values across other columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing potential duplicates.\n",
    "        id_cols (list): List of columns defining the unique ID.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame of rows with conflicting values.\n",
    "    \"\"\"\n",
    "    # Helper function to check for conflicts within each group\n",
    "    def has_conflicts(group):\n",
    "        for col in group.columns.difference(id_cols):\n",
    "            unique_values = group[col].dropna().unique()\n",
    "            if len(unique_values) > 1:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    # Group by ID columns and filter conflicting groups\n",
    "    conflicting_groups = df.groupby(id_cols).filter(has_conflicts)\n",
    "    return conflicting_groups\n",
    "\n",
    "def find_conflicting_columns(df, id_cols):\n",
    "    \"\"\"\n",
    "    Identify duplicate groups and the columns with conflicts.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame containing duplicates.\n",
    "        id_cols (list): List of columns defining the unique ID.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing duplicate groups with conflicting columns identified.\n",
    "    \"\"\"\n",
    "    def check_conflicts(group):\n",
    "        # Find columns where there are conflicting values\n",
    "        conflicting_columns = [\n",
    "            col for col in group.columns if col not in id_cols and group[col].nunique(dropna=True) > 1\n",
    "        ]\n",
    "        result = group.copy()\n",
    "        result[\"conflicting_columns\"] = \", \".join(conflicting_columns) if conflicting_columns else None\n",
    "        return result\n",
    "\n",
    "    # Identify duplicate groups and check for conflicts\n",
    "    duplicate_groups = df[df.duplicated(subset=id_cols, keep=False)]\n",
    "    conflicting_groups = duplicate_groups.groupby(id_cols, group_keys=False).apply(check_conflicts)\n",
    "    conflicting_groups = conflicting_groups.reset_index(drop=True)\n",
    "\n",
    "    return conflicting_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "conflicting = find_conflicting_duplicates(ara, ['pond_id', 'sample_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped = resolve_duplicates(ara, ['pond_id', 'sample_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\squaade\\AppData\\Local\\Temp\\ipykernel_23156\\845596098.py:94: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  conflicting_groups = duplicate_groups.groupby(id_cols, group_keys=False).apply(check_conflicts)\n"
     ]
    }
   ],
   "source": [
    "conflicting_cols = find_conflicting_columns(ara, ['pond_id', 'sample_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pond_id</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>group</th>\n",
       "      <th>treatment_group</th>\n",
       "      <th>name</th>\n",
       "      <th>measure_instrument</th>\n",
       "      <th>follow_up</th>\n",
       "      <th>weather</th>\n",
       "      <th>do_mg_per_L</th>\n",
       "      <th>ph</th>\n",
       "      <th>...</th>\n",
       "      <th>fish_help_method</th>\n",
       "      <th>readings_communicated_today</th>\n",
       "      <th>actions_taken</th>\n",
       "      <th>details</th>\n",
       "      <th>wind</th>\n",
       "      <th>disease_outbreak</th>\n",
       "      <th>lice_infestation</th>\n",
       "      <th>vegetation_in_water</th>\n",
       "      <th>sample_dt</th>\n",
       "      <th>conflicting_columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>WG-AJU1</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Test A (Farmer Measurements)</td>\n",
       "      <td>Treatment</td>\n",
       "      <td>Nagaraju P.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Light breeze (1-5 knots)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-08 07:35:00+05:30</td>\n",
       "      <td>group, in_range, submission_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>WG-AJU1</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Test A (Water Sample Analysis)</td>\n",
       "      <td>Treatment</td>\n",
       "      <td>Nagaraju P.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.72</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Light breeze (1-5 knots)</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-08 07:35:00+05:30</td>\n",
       "      <td>group, in_range, submission_id</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pond_id time_of_day                           group treatment_group  \\\n",
       "578  WG-AJU1     Morning    Test A (Farmer Measurements)       Treatment   \n",
       "579  WG-AJU1     Morning  Test A (Water Sample Analysis)       Treatment   \n",
       "\n",
       "            name measure_instrument follow_up weather  do_mg_per_L    ph  ...  \\\n",
       "578  Nagaraju P.                NaN     False     NaN          NaN   NaN  ...   \n",
       "579  Nagaraju P.                NaN     False     NaN          1.1  7.72  ...   \n",
       "\n",
       "     fish_help_method  readings_communicated_today actions_taken details  \\\n",
       "578               NaN                          NaN           NaN     NaN   \n",
       "579               NaN                          NaN           NaN     NaN   \n",
       "\n",
       "                         wind  disease_outbreak  lice_infestation  \\\n",
       "578  Light breeze (1-5 knots)             False             False   \n",
       "579  Light breeze (1-5 knots)             False             False   \n",
       "\n",
       "    vegetation_in_water                 sample_dt  \\\n",
       "578                 NaN 2022-12-08 07:35:00+05:30   \n",
       "579                 NaN 2022-12-08 07:35:00+05:30   \n",
       "\n",
       "                conflicting_columns  \n",
       "578  group, in_range, submission_id  \n",
       "579  group, in_range, submission_id  \n",
       "\n",
       "[2 rows x 88 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflicting_cols[conflicting_cols['conflicting_columns'].str.contains('in_range') &\n",
    "                 conflicting_cols['conflicting_columns'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'corrective_actions_taken',\n",
       " 'group',\n",
       " 'in_range',\n",
       " 'lice_infestation',\n",
       " 'params_out_of_range',\n",
       " 'submission_id',\n",
       " 'vegetation_in_water',\n",
       " 'wind'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "conflict_colnames = conflicting_cols['conflicting_columns'].str.split(\", \").tolist()\n",
    "conflict_colnames = set(itertools.chain.from_iterable([l for l in conflict_colnames if isinstance(l, list)]))\n",
    "conflict_colnames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, these are all variables that you trust. This means creating your own in_range measures and maybe not using the group variable. We will see if that's possible.\n",
    "\n",
    "For now just proceed and save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\squaade\\AppData\\Local\\Temp\\ipykernel_23156\\845596098.py:42: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(resolve_group)\n"
     ]
    }
   ],
   "source": [
    "ara_deduped = resolve_duplicates(ara, ['pond_id', 'sample_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_cols = ['pond_id', 'group', 'treatment_group', 'sample_dt', 'time_of_day']\n",
    "ara_deduped = ara_deduped[front_cols + [col for col in ara.columns if col not in front_cols]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get duplicates to send to Jennifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\squaade\\AppData\\Local\\Temp\\ipykernel_23156\\845596098.py:94: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  conflicting_groups = duplicate_groups.groupby(id_cols, group_keys=False).apply(check_conflicts)\n"
     ]
    }
   ],
   "source": [
    "duplicates = ara[ara.duplicated(['pond_id', 'sample_dt'], keep=False)] \\\n",
    "  .sort_values(['pond_id', 'sample_dt']) \\\n",
    "  .reset_index() \\\n",
    "  .pipe(find_conflicting_columns, id_cols=['pond_id', 'sample_dt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "front_cols = ['index', 'conflicting_columns', 'pond_id', 'group', 'treatment_group', 'sample_dt', 'time_of_day']\n",
    "duplicates = duplicates[front_cols + [col for col in duplicates.columns if col not in front_cols]]\n",
    "duplicates['sample_dt'] = duplicates['sample_dt'] \\\n",
    "  .dt.tz_localize(None) \\\n",
    "  .dt.strftime(\"%Y-%m-%d %H:%M:%S\") # To save as excel\n",
    "\n",
    "duplicates.to_excel(\"../data/clean/ara_data_josiah_duplicates.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
