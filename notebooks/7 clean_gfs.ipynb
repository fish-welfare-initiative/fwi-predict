{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean raw GFS download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs = pd.read_csv('../data/raw/gfs_forecast.csv').drop(columns=['system:index', '.geo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs['forecast_creation_dt'] = pd.to_datetime(gfs['forecast_creation_dt'].astype(str), format='%Y%m%d%H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    4961\n",
       "4       7\n",
       "3       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gfs.groupby('sample_idx').size().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A handful are not getting all of the measurements. Let's find those later, but don't worry too much for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create timing variables\n",
    "gfs['forecast_dt'] = gfs['forecast_creation_dt'] + pd.Series(pd.to_timedelta(gfs['forecast_hours'], unit='hour'), index=gfs.index)\n",
    "gfs['forecast_date'] = gfs['forecast_dt'].dt.date\n",
    "gfs['forecast_hour'] = gfs['forecast_dt'].dt.hour\n",
    "\n",
    "# Reorder columns\n",
    "front_cols = ['sample_idx', 'forecast_dt', 'forecast_date', 'forecast_hour', 'forecast_creation_dt'] \n",
    "gfs = gfs[front_cols + [col for col in gfs.columns if col not in front_cols]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep those with correct number of data points for now\n",
    "gfs = gfs[gfs.groupby('sample_idx')['sample_idx'].transform(len) == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename forecast values from sample time to 'sample\n",
    "gfs = gfs \\\n",
    "  .sort_values(['sample_idx', 'forecast_dt'])\n",
    "gfs.loc[gfs.groupby('sample_idx').tail(1).index, 'forecast_hour'] = 'sample'\n",
    "\n",
    "# Pivot data wide so each row is a measurement\n",
    "gfs_wide = gfs \\\n",
    "  .drop(columns=['forecast_creation_dt', 'forecast_hours', 'forecast_date', 'forecast_dt']) \\\n",
    "  .pivot(index='sample_idx', columns='forecast_hour')\n",
    "gfs_wide.columns = gfs_wide.columns.map('{0[0]}_{0[1]}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfs_wide.to_csv('../data/clean/gfs_forecasts.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
